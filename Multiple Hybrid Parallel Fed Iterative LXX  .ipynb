{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 20:56:25.911898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 2ms/step\n",
      "Local Model Results for Node 0 - CO with Weighted Predictions:\n",
      "MSE for LSTM_1: 206.41255059480218\n",
      "MSE for XGB_2: 89.05519876455325\n",
      "MSE for XGB_3: 87.89050290880817\n",
      "RMSE for XGB_3: 9.374993488467508\n",
      "R2 for XGB_3: 0.49921073109585967\n",
      "EVS for XGB_3: 0.49921075892015265\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - O3 with Weighted Predictions:\n",
      "MSE for LSTM_1: 1268.2620245925903\n",
      "MSE for XGB_2: 234.2920838881427\n",
      "MSE for XGB_3: 233.28963815136527\n",
      "RMSE for XGB_3: 15.273821988990354\n",
      "R2 for XGB_3: 0.8181785668628083\n",
      "EVS for XGB_3: 0.8181785668633166\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - NO2 with Weighted Predictions:\n",
      "MSE for LSTM_1: 547.8860450386782\n",
      "MSE for XGB_2: 337.803022436783\n",
      "MSE for XGB_3: 336.6361423038784\n",
      "RMSE for XGB_3: 18.347646778371292\n",
      "R2 for XGB_3: 0.3805246393230256\n",
      "EVS for XGB_3: 0.3805246399508958\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - SO2 with Weighted Predictions:\n",
      "MSE for LSTM_1: 308.54887063676915\n",
      "MSE for XGB_2: 122.77253946184041\n",
      "MSE for XGB_3: 121.8714615122703\n",
      "RMSE for XGB_3: 11.039540819810863\n",
      "R2 for XGB_3: 0.6017221842077665\n",
      "EVS for XGB_3: 0.6017221900030643\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - PM10 with Weighted Predictions:\n",
      "MSE for LSTM_1: 564.7167944976765\n",
      "MSE for XGB_2: 162.29555327338878\n",
      "MSE for XGB_3: 161.3665083611534\n",
      "RMSE for XGB_3: 12.703011783083308\n",
      "R2 for XGB_3: 0.7040552001549498\n",
      "EVS for XGB_3: 0.7040552005971488\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - PM2.5 with Weighted Predictions:\n",
      "MSE for LSTM_1: 1216.7601866076923\n",
      "MSE for XGB_2: 308.22576846994997\n",
      "MSE for XGB_3: 307.17707455548305\n",
      "RMSE for XGB_3: 17.526467828843412\n",
      "R2 for XGB_3: 0.7399856579918165\n",
      "EVS for XGB_3: 0.7399856579920856\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - AQI with Weighted Predictions:\n",
      "MSE for LSTM_1: 1221.4218716550404\n",
      "MSE for XGB_2: 498.4430622683577\n",
      "MSE for XGB_3: 497.35881170417395\n",
      "RMSE for XGB_3: 22.30154280995317\n",
      "R2 for XGB_3: 0.58980822056553\n",
      "EVS for XGB_3: 0.5898082206869213\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - Highest tempreture: 12pm with Weighted Predictions:\n",
      "MSE for LSTM_1: 116.38786875743494\n",
      "MSE for XGB_2: 1.2039942222905533\n",
      "MSE for XGB_3: 0.931778258799912\n",
      "RMSE for XGB_3: 0.9652866200253228\n",
      "R2 for XGB_3: 0.9922993234881095\n",
      "EVS for XGB_3: 0.9922993261264307\n",
      "51/51 [==============================] - 0s 1ms/step\n",
      "Local Model Results for Node 0 - Wind:km/h with Weighted Predictions:\n",
      "MSE for LSTM_1: 57.507552636998504\n",
      "MSE for XGB_2: 9.87385655583062\n",
      "MSE for XGB_3: 9.085163270194888\n",
      "RMSE for XGB_3: 3.0141604586011823\n",
      "R2 for XGB_3: 0.8430855763496704\n",
      "EVS for XGB_3: 0.8430855764301819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Model Results:\n",
      "Mean Squared Error (MSE) for Global Model: 195.15350801074726\n",
      "Duration of the program execution: 158.62399792671204 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import the time module\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the folder path where the 22 files are located\n",
    "folder_path = ''\n",
    "\n",
    "# Initialize an empty list to store all the dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through each file in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the Excel file into a dataframe\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Convert 'iranidate' to datetime and handle missing values\n",
    "        df['iranidate'] = pd.to_datetime(df['iranidate'], errors='coerce')\n",
    "        \n",
    "        def convert_to_numeric_date(date):\n",
    "            base_date = datetime(2000, 1, 1)\n",
    "            return (date - base_date).days\n",
    "        df['iranidate'] = df['iranidate'].apply(convert_to_numeric_date)\n",
    "        \n",
    "        # Encode 'node' column\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['node_encoded'] = label_encoder.fit_transform(df['node'])\n",
    "        \n",
    "        # Handling NaN values by finding the nearest non-empty cells in the same column\n",
    "        for col in ['CO', 'O3', 'SO2', 'PM10', 'PM2.5', 'AQI']:\n",
    "            for idx, value in df[col].items():\n",
    "                if pd.isnull(value):  \n",
    "                    upper_cell = df[col].iloc[:idx].last_valid_index()  \n",
    "                    lower_cell = df[col].iloc[idx + 1:].first_valid_index()  \n",
    "                    if upper_cell is not None and lower_cell is not None:  \n",
    "                        avg = (df.at[upper_cell, col] + df.at[lower_cell, col]) / 2  \n",
    "                        df.at[idx, col] = avg  \n",
    "        \n",
    "        # Append the modified dataframe to the list\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Check sample threshold\n",
    "your_threshold_value = 100\n",
    "if len(df) < your_threshold_value:\n",
    "    print(\"Insufficient samples in the dataset.\")\n",
    "else:\n",
    "    output_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5', 'AQI', 'Highest tempreture: 12pm', 'Wind:km/h']\n",
    "    unique_nodes = df['node_encoded'].unique()  \n",
    "\n",
    "    # Dictionary to store weighted predictions for each node and column\n",
    "    weighted_predictions = {}\n",
    "    \n",
    "    lstm_model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=(2, 1)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    lstm_model.compile(optimizer='adam', loss='mse')\n",
    "    xgb_model_2 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "    xgb_model_3 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "\n",
    "    for node_value in unique_nodes:\n",
    "        node_df = df[df['node_encoded'] == node_value]  \n",
    "        \n",
    "        # Dictionary to store predictions and true values for each column\n",
    "        columns_data = {}\n",
    "\n",
    "        for output_column in output_columns:\n",
    "            if node_df[output_column].isnull().any():\n",
    "                print(f\"NaN values found in {output_column} for Node {node_value}. Handle missing values before modeling.\")\n",
    "            else:\n",
    "                # Modify X to include the 'node' column along with 'iranidate'\n",
    "                X = node_df[['iranidate', 'node_encoded']]\n",
    "                Y = node_df[[output_column]]  \n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Reshape the input data for LSTM\n",
    "                X_train_lstm = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "                X_test_lstm = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "                lstm_model.fit(X_train_lstm, Y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "                # Predict using the LSTM model\n",
    "                Y1_pred_lstm = lstm_model.predict(X_test_lstm)\n",
    "\n",
    "                # Flatten the LSTM predictions for input to XGBoost model\n",
    "                Y1_pred_lstm_flat = Y1_pred_lstm.flatten()\n",
    "\n",
    "                xgb_model_2.fit(np.concatenate((X_test, Y1_pred_lstm_flat.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y2_pred_xgb = xgb_model_2.predict(np.concatenate((X_test, Y1_pred_lstm_flat.reshape(-1, 1)), axis=1))\n",
    "\n",
    "                xgb_model_3.fit(np.concatenate((X_test, Y2_pred_xgb.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y3_pred_xgb = xgb_model_3.predict(np.concatenate((X_test, Y2_pred_xgb.reshape(-1, 1)), axis=1))\n",
    "\n",
    "                # Calculate errors for the third XGBoost model\n",
    "                mse_lstm_1 = mean_squared_error(Y_test, Y1_pred_lstm)\n",
    "                mse_xgb_2 = mean_squared_error(Y_test, Y2_pred_xgb)\n",
    "                mse_xgb_3 = mean_squared_error(Y_test, Y3_pred_xgb)\n",
    "                rmse_xgb_3 = np.sqrt(mse_xgb_3)\n",
    "                r2_xgb_3 = r2_score(Y_test, Y3_pred_xgb)\n",
    "                evs_xgb_3 = explained_variance_score(Y_test, Y3_pred_xgb)\n",
    "\n",
    "                # Store predictions and true values for each column in the dictionary\n",
    "                columns_data[output_column] = (Y3_pred_xgb, Y_test)\n",
    "\n",
    "                # Output results for the local model with weighted predictions\n",
    "                print(f\"Local Model Results for Node {node_value} - {output_column} with Weighted Predictions:\")\n",
    "                print(f\"MSE for LSTM_1: {mse_lstm_1}\")\n",
    "                print(f\"MSE for XGB_2: {mse_xgb_2}\")\n",
    "                print(f\"MSE for XGB_3: {mse_xgb_3}\")\n",
    "                print(f\"RMSE for XGB_3: {rmse_xgb_3}\")\n",
    "                print(f\"R2 for XGB_3: {r2_xgb_3}\")\n",
    "                print(f\"EVS for XGB_3: {evs_xgb_3}\")\n",
    "\n",
    "                # Store weighted predictions for each node and column\n",
    "                if node_value not in weighted_predictions:\n",
    "                    weighted_predictions[node_value] = {output_column: (Y3_pred_xgb, Y_test)}\n",
    "                else:\n",
    "                    weighted_predictions[node_value][output_column] = (Y3_pred_xgb, Y_test)\n",
    "\n",
    "# Aggregate predictions for the global model using weighted average\n",
    "global_X_test = []\n",
    "global_Y_test = []\n",
    "\n",
    "for node, columns in weighted_predictions.items():\n",
    "    for column, (node_prediction, Y_test) in columns.items():\n",
    "        global_X_test.extend(node_prediction * r2_xgb_3)  # Apply weights using the R2 score from the LSTM model\n",
    "        global_Y_test.extend(Y_test.values)\n",
    "\n",
    "# Create and train the global model (Random Forest)\n",
    "global_model = RandomForestRegressor(random_state=42)\n",
    "global_model.fit(np.array(global_X_test).reshape(-1, 1), global_Y_test)  # Reshape for RF\n",
    "\n",
    "# Predict using the global model\n",
    "global_Y_pred = global_model.predict(np.array(global_X_test).reshape(-1, 1))\n",
    "global_mse = mean_squared_error(global_Y_test, global_Y_pred)\n",
    "\n",
    "# Print results for the global model\n",
    "print(\"Global Model Results:\")\n",
    "print(f\"Mean Squared Error (MSE) for Global Model: {global_mse}\")\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration of the program execution\n",
    "duration_seconds = end_time - start_time\n",
    "\n",
    "# Print the duration of the program execution\n",
    "print(f\"Duration of the program execution: {duration_seconds} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

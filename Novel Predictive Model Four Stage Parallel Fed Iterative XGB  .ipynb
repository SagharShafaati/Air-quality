{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Model Results for Node 0 - CO with Weighted Predictions:\n",
      "MSE for XGB_1: 108.87770980872973\n",
      "MSE for XGB_2: 79.09272084888384\n",
      "MSE for XGB_3: 78.32795453676799\n",
      "MSE for XGB_4: 78.30586992694597\n",
      "RMSE for XGB_4: 8.849060397971412\n",
      "R2 for XGB_4: 0.55382279024725\n",
      "EVS for XGB_4: 0.5538227933171391\n",
      "Local Model Results for Node 0 - O3 with Weighted Predictions:\n",
      "MSE for XGB_1: 286.0230706674861\n",
      "MSE for XGB_2: 195.98568458529672\n",
      "MSE for XGB_3: 195.41329190107254\n",
      "MSE for XGB_4: 195.3861930392787\n",
      "RMSE for XGB_4: 13.978061133049845\n",
      "R2 for XGB_4: 0.8477197790903525\n",
      "EVS for XGB_4: 0.8477197791535164\n",
      "Local Model Results for Node 0 - NO2 with Weighted Predictions:\n",
      "MSE for XGB_1: 421.2842300152824\n",
      "MSE for XGB_2: 307.9520590697534\n",
      "MSE for XGB_3: 307.02740523439917\n",
      "MSE for XGB_4: 307.05590110222647\n",
      "RMSE for XGB_4: 17.52301061753449\n",
      "R2 for XGB_4: 0.4349579822846501\n",
      "EVS for XGB_4: 0.43495798228636207\n",
      "Local Model Results for Node 0 - SO2 with Weighted Predictions:\n",
      "MSE for XGB_1: 156.64310168137405\n",
      "MSE for XGB_2: 109.67182539901422\n",
      "MSE for XGB_3: 108.92090709621583\n",
      "MSE for XGB_4: 108.85720872311116\n",
      "RMSE for XGB_4: 10.43346580591086\n",
      "R2 for XGB_4: 0.6442529630358551\n",
      "EVS for XGB_4: 0.6442529630682701\n",
      "Local Model Results for Node 0 - PM10 with Weighted Predictions:\n",
      "MSE for XGB_1: 222.49228587376982\n",
      "MSE for XGB_2: 137.64029267658665\n",
      "MSE for XGB_3: 136.73982387580747\n",
      "MSE for XGB_4: 136.7414855725698\n",
      "RMSE for XGB_4: 11.693651507231168\n",
      "R2 for XGB_4: 0.7492172818927336\n",
      "EVS for XGB_4: 0.7492172819688456\n",
      "Local Model Results for Node 0 - PM2.5 with Weighted Predictions:\n",
      "MSE for XGB_1: 373.8752893398491\n",
      "MSE for XGB_2: 270.6133998708187\n",
      "MSE for XGB_3: 269.76188711627947\n",
      "MSE for XGB_4: 269.7911678274198\n",
      "RMSE for XGB_4: 16.42532093529438\n",
      "R2 for XGB_4: 0.7716314829686438\n",
      "EVS for XGB_4: 0.771631482968982\n",
      "Local Model Results for Node 0 - AQI with Weighted Predictions:\n",
      "MSE for XGB_1: 609.1879254660737\n",
      "MSE for XGB_2: 458.98774367314104\n",
      "MSE for XGB_3: 458.3416895692768\n",
      "MSE for XGB_4: 458.2451400889997\n",
      "RMSE for XGB_4: 21.406661114919338\n",
      "R2 for XGB_4: 0.6220668358398217\n",
      "EVS for XGB_4: 0.6220668360003934\n",
      "Local Model Results for Node 0 - Highest tempreture: 12pm with Weighted Predictions:\n",
      "MSE for XGB_1: 0.9787873095175575\n",
      "MSE for XGB_2: 0.45411691041599017\n",
      "MSE for XGB_3: 0.3639343104404469\n",
      "MSE for XGB_4: 0.3380294385384263\n",
      "RMSE for XGB_4: 0.5814029915114183\n",
      "R2 for XGB_4: 0.9972063574857037\n",
      "EVS for XGB_4: 0.9972063574891813\n",
      "Local Model Results for Node 0 - Wind:km/h with Weighted Predictions:\n",
      "MSE for XGB_1: 6.431013678553919\n",
      "MSE for XGB_2: 2.792732204148741\n",
      "MSE for XGB_3: 2.466643564357837\n",
      "MSE for XGB_4: 2.446614022645965\n",
      "RMSE for XGB_4: 1.564165599495771\n",
      "R2 for XGB_4: 0.9577432988444169\n",
      "EVS for XGB_4: 0.9577432988448666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Model Results:\n",
      "Mean Squared Error (MSE) for Global Model: 173.009414536412\n",
      "Duration of the program execution: 6.965367078781128 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import the time module\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the folder path where the 22 files are located\n",
    "folder_path = ''\n",
    "\n",
    "# Initialize an empty list to store all the dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through each file in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the Excel file into a dataframe\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Convert 'iranidate' to datetime and handle missing values\n",
    "        df['iranidate'] = pd.to_datetime(df['iranidate'], errors='coerce')\n",
    "        \n",
    "        def convert_to_numeric_date(date):\n",
    "            base_date = datetime(2000, 1, 1)\n",
    "            return (date - base_date).days\n",
    "        df['iranidate'] = df['iranidate'].apply(convert_to_numeric_date)\n",
    "        \n",
    "        # Encode 'node' column\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['node_encoded'] = label_encoder.fit_transform(df['node'])\n",
    "        \n",
    "        # Handling NaN values by finding the nearest non-empty cells in the same column\n",
    "        for col in ['CO', 'O3', 'SO2', 'PM10', 'PM2.5', 'AQI']:\n",
    "            for idx, value in df[col].items():\n",
    "                if pd.isnull(value):  \n",
    "                    upper_cell = df[col].iloc[:idx].last_valid_index()  \n",
    "                    lower_cell = df[col].iloc[idx + 1:].first_valid_index()  \n",
    "                    if upper_cell is not None and lower_cell is not None:  \n",
    "                        avg = (df.at[upper_cell, col] + df.at[lower_cell, col]) / 2  \n",
    "                        df.at[idx, col] = avg  \n",
    "        \n",
    "        # Append the modified dataframe to the list\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Check sample threshold\n",
    "your_threshold_value = 100\n",
    "if len(df) < your_threshold_value:\n",
    "    print(\"Insufficient samples in the dataset.\")\n",
    "else:\n",
    "    output_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5', 'AQI', 'Highest tempreture: 12pm', 'Wind:km/h']\n",
    "    unique_nodes = df['node_encoded'].unique()  \n",
    "\n",
    "    # Dictionary to store weighted predictions for each node and column\n",
    "    weighted_predictions = {}\n",
    "\n",
    "    xgb_model_1 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "    xgb_model_2 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "    xgb_model_3 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "    xgb_model_4 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "\n",
    "    for node_value in unique_nodes:\n",
    "        node_df = df[df['node_encoded'] == node_value]  \n",
    "        \n",
    "        # Dictionary to store predictions and true values for each column\n",
    "        columns_data = {}\n",
    "\n",
    "        for output_column in output_columns:\n",
    "            if node_df[output_column].isnull().any():\n",
    "                print(f\"NaN values found in {output_column} for Node {node_value}. Handle missing values before modeling.\")\n",
    "            else:\n",
    "                # Modify X to include the 'node' column along with 'iranidate'\n",
    "                X = node_df[['iranidate', 'node_encoded']]\n",
    "                Y = node_df[[output_column]]  \n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "                xgb_model_1.fit(X_train, Y_train)\n",
    "                Y1_pred_xgb = xgb_model_1.predict(X_test)\n",
    "            \n",
    "                xgb_model_2.fit(np.concatenate((X_test, Y1_pred_xgb.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y2_pred_xgb = xgb_model_2.predict(np.concatenate((X_test, Y1_pred_xgb.reshape(-1, 1)), axis=1))\n",
    "\n",
    "                xgb_model_3.fit(np.concatenate((X_test, Y2_pred_xgb.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y3_pred_xgb = xgb_model_3.predict(np.concatenate((X_test, Y2_pred_xgb.reshape(-1, 1)), axis=1))\n",
    "\n",
    "                xgb_model_4.fit(np.concatenate((X_test, Y3_pred_xgb.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y4_pred_xgb = xgb_model_4.predict(np.concatenate((X_test, Y3_pred_xgb.reshape(-1, 1)), axis=1))\n",
    "\n",
    "\n",
    "                # Calculate errors for the fourth XGBoost model\n",
    "                mse_xgb_1 = mean_squared_error(Y_test, Y1_pred_xgb)\n",
    "                mse_xgb_2 = mean_squared_error(Y_test, Y2_pred_xgb)\n",
    "                mse_xgb_3 = mean_squared_error(Y_test, Y3_pred_xgb)\n",
    "                mse_xgb_4 = mean_squared_error(Y_test, Y4_pred_xgb)\n",
    "                rmse_xgb_4 = np.sqrt(mse_xgb_4)\n",
    "                r2_xgb_4 = r2_score(Y_test, Y4_pred_xgb)\n",
    "                evs_xgb_4 = explained_variance_score(Y_test, Y4_pred_xgb)\n",
    "\n",
    "                # Store predictions and true values for each column in the dictionary\n",
    "                columns_data[output_column] = (Y4_pred_xgb, Y_test)\n",
    "\n",
    "                # Output results for the local model with weighted predictions\n",
    "                print(f\"Local Model Results for Node {node_value} - {output_column} with Weighted Predictions:\")\n",
    "                print(f\"MSE for XGB_1: {mse_xgb_1}\")\n",
    "                print(f\"MSE for XGB_2: {mse_xgb_2}\")\n",
    "                print(f\"MSE for XGB_3: {mse_xgb_3}\")\n",
    "                print(f\"MSE for XGB_4: {mse_xgb_4}\")\n",
    "                print(f\"RMSE for XGB_4: {rmse_xgb_4}\")\n",
    "                print(f\"R2 for XGB_4: {r2_xgb_4}\")\n",
    "                print(f\"EVS for XGB_4: {evs_xgb_4}\")\n",
    "\n",
    "                #   Store weighted predictions for each node and column\n",
    "                if node_value not in weighted_predictions:\n",
    "                    weighted_predictions[node_value] = {output_column: (Y4_pred_xgb, Y_test)}\n",
    "                else:\n",
    "                    weighted_predictions[node_value][output_column] = (Y4_pred_xgb, Y_test)\n",
    "\n",
    "\n",
    "# Aggregate predictions for the global model using weighted average\n",
    "global_X_test = []\n",
    "global_Y_test = []\n",
    "\n",
    "for node, columns in weighted_predictions.items():\n",
    "    for column, (node_prediction, Y_test) in columns.items():\n",
    "        global_X_test.extend(node_prediction * r2_xgb_4)  # Apply weights using the R2 score from the fourth XGBoost model\n",
    "        global_Y_test.extend(Y_test.values)\n",
    "\n",
    "# Create and train the global model (Random Forest)\n",
    "global_model = RandomForestRegressor(random_state=42)\n",
    "global_model.fit(np.array(global_X_test).reshape(-1, 1), global_Y_test)  # Reshape for RF\n",
    "\n",
    "# Predict using the global model\n",
    "global_Y_pred = global_model.predict(np.array(global_X_test).reshape(-1, 1))\n",
    "global_mse = mean_squared_error(global_Y_test, global_Y_pred)\n",
    "\n",
    "# Print results for the global model\n",
    "print(\"Global Model Results:\")\n",
    "print(f\"Mean Squared Error (MSE) for Global Model: {global_mse}\")\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration of the program execution\n",
    "duration_seconds = end_time - start_time\n",
    "\n",
    "# Print the duration of the program execution\n",
    "print(f\"Duration of the program execution: {duration_seconds} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

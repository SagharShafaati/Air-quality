{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Model Results for Node 0 - CO with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 108.87770980872973\n",
      "MSE for XGBoost (second Model): 79.09272084888384\n",
      "MSE for XGBoost (Third Model): 78.32795453676799\n",
      "RMSE for XGBoost (Third Model): 8.850308160553958\n",
      "R2 for XGBoost (Third Model): 0.5536969548584336\n",
      "EVS for XGBoost (Third Model): 0.553696955066949\n",
      "Local Model Results for Node 0 - O3 with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 286.0230706674861\n",
      "MSE for XGBoost (second Model): 195.98568458529672\n",
      "MSE for XGBoost (Third Model): 195.41329190107254\n",
      "RMSE for XGBoost (Third Model): 13.979030434943352\n",
      "R2 for XGBoost (Third Model): 0.8476986587614481\n",
      "EVS for XGBoost (Third Model): 0.8476986587619935\n",
      "Local Model Results for Node 0 - NO2 with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 421.2842300152824\n",
      "MSE for XGBoost (second Model): 307.9520590697534\n",
      "MSE for XGBoost (Third Model): 307.02740523439917\n",
      "RMSE for XGBoost (Third Model): 17.522197500153887\n",
      "R2 for XGBoost (Third Model): 0.43501042017167946\n",
      "EVS for XGBoost (Third Model): 0.43501042188028116\n",
      "Local Model Results for Node 0 - SO2 with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 156.64310168137405\n",
      "MSE for XGBoost (second Model): 109.67182539901422\n",
      "MSE for XGBoost (Third Model): 108.92090709621583\n",
      "RMSE for XGBoost (Third Model): 10.436517958410066\n",
      "R2 for XGBoost (Third Model): 0.6440447957701569\n",
      "EVS for XGBoost (Third Model): 0.6440447958045616\n",
      "Local Model Results for Node 0 - PM10 with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 222.49228587376982\n",
      "MSE for XGBoost (second Model): 137.64029267658665\n",
      "MSE for XGBoost (Third Model): 136.73982387580747\n",
      "RMSE for XGBoost (Third Model): 11.69358045578032\n",
      "R2 for XGBoost (Third Model): 0.7492203294304212\n",
      "EVS for XGBoost (Third Model): 0.7492203294305273\n",
      "Local Model Results for Node 0 - PM2.5 with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 373.8752893398491\n",
      "MSE for XGBoost (second Model): 270.6133998708187\n",
      "MSE for XGBoost (Third Model): 269.76188711627947\n",
      "RMSE for XGBoost (Third Model): 16.424429582675906\n",
      "R2 for XGBoost (Third Model): 0.771656268037164\n",
      "EVS for XGBoost (Third Model): 0.771656268453339\n",
      "Local Model Results for Node 0 - AQI with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 609.1879254660737\n",
      "MSE for XGBoost (second Model): 458.98774367314104\n",
      "MSE for XGBoost (Third Model): 458.3416895692768\n",
      "RMSE for XGBoost (Third Model): 21.408916123178138\n",
      "R2 for XGBoost (Third Model): 0.6219872076072733\n",
      "EVS for XGBoost (Third Model): 0.6219872076259172\n",
      "Local Model Results for Node 0 - Highest tempreture: 12pm with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 0.9787873095175575\n",
      "MSE for XGBoost (second Model): 0.45411691041599017\n",
      "MSE for XGBoost (Third Model): 0.3639343104404469\n",
      "RMSE for XGBoost (Third Model): 0.6032696830112109\n",
      "R2 for XGBoost (Third Model): 0.9969922668083183\n",
      "EVS for XGBoost (Third Model): 0.9969922671816437\n",
      "Local Model Results for Node 0 - Wind:km/h with Weighted Predictions:\n",
      "MSE for XGBoost (first Model): 6.431013678553919\n",
      "MSE for XGBoost (second Model): 2.792732204148741\n",
      "MSE for XGBoost (Third Model): 2.466643564357837\n",
      "RMSE for XGBoost (Third Model): 1.5705551771134425\n",
      "R2 for XGBoost (Third Model): 0.9573973585569143\n",
      "EVS for XGBoost (Third Model): 0.9573973702999491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Model Results:\n",
      "Mean Squared Error (MSE) for Global Model: 173.01246429349823\n",
      "Duration of the program execution: 20.72672200202942 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import the time module\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the folder path where the 22 files are located\n",
    "folder_path = ''\n",
    "\n",
    "# Initialize an empty list to store all the dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through each file in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the Excel file into a dataframe\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Convert 'iranidate' to datetime and handle missing values\n",
    "        df['iranidate'] = pd.to_datetime(df['iranidate'], errors='coerce')\n",
    "        \n",
    "        def convert_to_numeric_date(date):\n",
    "            base_date = datetime(2000, 1, 1)\n",
    "            return (date - base_date).days\n",
    "        df['iranidate'] = df['iranidate'].apply(convert_to_numeric_date)\n",
    "        \n",
    "        # Encode 'node' column\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['node_encoded'] = label_encoder.fit_transform(df['node'])\n",
    "        \n",
    "        # Handling NaN values by finding the nearest non-empty cells in the same column\n",
    "        for col in ['CO', 'O3', 'SO2', 'PM10', 'PM2.5', 'AQI']:\n",
    "            for idx, value in df[col].items():\n",
    "                if pd.isnull(value):  \n",
    "                    upper_cell = df[col].iloc[:idx].last_valid_index()  \n",
    "                    lower_cell = df[col].iloc[idx + 1:].first_valid_index()  \n",
    "                    if upper_cell is not None and lower_cell is not None:  \n",
    "                        avg = (df.at[upper_cell, col] + df.at[lower_cell, col]) / 2  \n",
    "                        df.at[idx, col] = avg  \n",
    "        \n",
    "        # Append the modified dataframe to the list\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Check sample threshold\n",
    "your_threshold_value = 100\n",
    "if len(df) < your_threshold_value:\n",
    "    print(\"Insufficient samples in the dataset.\")\n",
    "else:\n",
    "    output_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5', 'AQI', 'Highest tempreture: 12pm', 'Wind:km/h']\n",
    "    unique_nodes = df['node_encoded'].unique()  \n",
    "\n",
    "    # Dictionary to store weighted predictions for each node and column\n",
    "    weighted_predictions = {}\n",
    "\n",
    "    # Dictionary to store weighted predictions for each node and column\n",
    "    weighted_predictions = {}\n",
    "    xgb_model_1 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "    xgb_model_2 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "    xgb_model_3 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.3, max_depth=10, alpha=10, n_estimators=200)\n",
    "\n",
    "    for node_value in unique_nodes:\n",
    "        node_df = df[df['node_encoded'] == node_value]  \n",
    "        \n",
    "        # Dictionary to store predictions and true values for each column\n",
    "        columns_data = {}\n",
    "\n",
    "        for output_column in output_columns:\n",
    "            if node_df[output_column].isnull().any():\n",
    "                print(f\"NaN values found in {output_column} for Node {node_value}. Handle missing values before modeling.\")\n",
    "            else:\n",
    "                # Modify X to include the 'node' column along with 'iranidate'\n",
    "                X = node_df[['iranidate', 'node_encoded']]\n",
    "                Y = node_df[[output_column]]  \n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "                xgb_model_1.fit(X_train, Y_train)\n",
    "                Y1_pred_xgb = xgb_model_1.predict(X_test)\n",
    "            \n",
    "                xgb_model_2.fit(np.concatenate((X_test, Y1_pred_xgb.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y2_pred_xgb = xgb_model_2.predict(np.concatenate((X_test, Y1_pred_xgb.reshape(-1, 1)), axis=1))\n",
    "\n",
    "                xgb_model_3.fit(np.concatenate((X_test, Y2_pred_xgb.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y3_pred_xgb = xgb_model_3.predict(np.concatenate((X_test, Y2_pred_xgb.reshape(-1, 1)), axis=1))\n",
    "        \n",
    "\n",
    "                # Calculate errors for the third XGBoost model\n",
    "                mse_xgb_1 = mean_squared_error(Y_test, Y1_pred_xgb)\n",
    "                mse_xgb_2 = mean_squared_error(Y_test, Y2_pred_xgb)\n",
    "                mse_xgb_3 = mean_squared_error(Y_test, Y3_pred_xgb)\n",
    "                rmse_xgb_3 = np.sqrt(mse_xgb_3)\n",
    "                r2_xgb_1 = r2_score(Y_test, Y1_pred_xgb)\n",
    "                r2_xgb_2 = r2_score(Y_test, Y2_pred_xgb)\n",
    "                r2_xgb_3 = r2_score(Y_test, Y3_pred_xgb)\n",
    "                evs_xgb_3 = explained_variance_score(Y_test, Y3_pred_xgb)\n",
    "\n",
    "                # Store predictions and true values for each column in the dictionary\n",
    "                columns_data[output_column] = (Y3_pred_xgb, Y_test)\n",
    "\n",
    "                # Output results for the local model with weighted predictions\n",
    "                print(f\"Local Model Results for Node {node_value} - {output_column} with Weighted Predictions:\")\n",
    "                print(f\"MSE for XGBoost (first Model): {mse_xgb_1}\")\n",
    "                print(f\"MSE for XGBoost (second Model): {mse_xgb_2}\")\n",
    "                print(f\"MSE for XGBoost (Third Model): {mse_xgb_3}\")\n",
    "                print(f\"RMSE for XGBoost (Third Model): {rmse_xgb_3}\")\n",
    "                print(f\"R2 for XGBoost (First Model): {r2_xgb_1}\")\n",
    "                print(f\"R2 for XGBoost (Second Model): {r2_xgb_2}\")\n",
    "                print(f\"R2 for XGBoost (Third Model): {r2_xgb_3}\")\n",
    "                print(f\"EVS for XGBoost (Third Model): {evs_xgb_3}\")\n",
    "\n",
    "                # Store weighted predictions for each node and column\n",
    "                if node_value not in weighted_predictions:\n",
    "                    weighted_predictions[node_value] = {output_column: (Y3_pred_xgb, Y_test)}\n",
    "                else:\n",
    "                    weighted_predictions[node_value][output_column] = (Y3_pred_xgb, Y_test)\n",
    "\n",
    "# Aggregate predictions for the global model using weighted average\n",
    "global_X_test = []\n",
    "global_Y_test = []\n",
    "\n",
    "for node, columns in weighted_predictions.items():\n",
    "    for column, (node_prediction, Y_test) in columns.items():\n",
    "        global_X_test.extend(node_prediction * r2_xgb_3)  # Apply weights using the R2 score from the third XGBoost model\n",
    "        global_Y_test.extend(Y_test.values)\n",
    "\n",
    "# Create and train the global model (Random Forest)\n",
    "global_model = RandomForestRegressor(random_state=42)\n",
    "global_model.fit(np.array(global_X_test).reshape(-1, 1), global_Y_test)  # Reshape for RF\n",
    "\n",
    "# Predict using the global model\n",
    "global_Y_pred = global_model.predict(np.array(global_X_test).reshape(-1, 1))\n",
    "global_mse = mean_squared_error(global_Y_test, global_Y_pred)\n",
    "\n",
    "# Print results for the global model\n",
    "print(\"Global Model Results:\")\n",
    "print(f\"Mean Squared Error (MSE) for Global Model: {global_mse}\")\n",
    "\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration of the program execution\n",
    "duration_seconds = end_time - start_time\n",
    "\n",
    "# Print the duration of the program execution\n",
    "print(f\"Duration of the program execution: {duration_seconds} seconds\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

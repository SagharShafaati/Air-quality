{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 21:31:59.150560: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Model Results for Node 0 - CO with Weighted Predictions:\n",
      "MSE for XGB_1: 115.5933415204187\n",
      "MSE for XGB_2: 89.00291054645788\n",
      "RMSE for XGB_1: 10.75143439362482\n",
      "RMSE for XGB_2: 9.434135389449205\n",
      "R2 for XGB_2: 0.49287236928036304\n",
      "EVS for XGB_2: 0.4928723764201396\n",
      "Local Model Results for Node 0 - O3 with Weighted Predictions:\n",
      "MSE for XGB_1: 309.91070735402917\n",
      "MSE for XGB_2: 213.5676149051528\n",
      "RMSE for XGB_1: 17.604280938283992\n",
      "RMSE for XGB_2: 14.613952747465444\n",
      "R2 for XGB_2: 0.8335495304401308\n",
      "EVS for XGB_2: 0.8335495305311325\n",
      "Local Model Results for Node 0 - NO2 with Weighted Predictions:\n",
      "MSE for XGB_1: 427.5663739274933\n",
      "MSE for XGB_2: 345.34557491500254\n",
      "RMSE for XGB_1: 20.67767815610576\n",
      "RMSE for XGB_2: 18.583475856658318\n",
      "R2 for XGB_2: 0.3644976052941077\n",
      "EVS for XGB_2: 0.3644976075213432\n",
      "Local Model Results for Node 0 - SO2 with Weighted Predictions:\n",
      "MSE for XGB_1: 161.26090530757554\n",
      "MSE for XGB_2: 115.36009031379925\n",
      "RMSE for XGB_1: 12.698854488007001\n",
      "RMSE for XGB_2: 10.740581470004278\n",
      "R2 for XGB_2: 0.6230014457063939\n",
      "EVS for XGB_2: 0.6230015687008947\n",
      "Local Model Results for Node 0 - PM10 with Weighted Predictions:\n",
      "MSE for XGB_1: 241.16796984491012\n",
      "MSE for XGB_2: 154.11397511086875\n",
      "RMSE for XGB_1: 15.529583698377433\n",
      "RMSE for XGB_2: 12.414264984720955\n",
      "R2 for XGB_2: 0.7173562842703807\n",
      "EVS for XGB_2: 0.7173562849872402\n",
      "Local Model Results for Node 0 - PM2.5 with Weighted Predictions:\n",
      "MSE for XGB_1: 392.7268804064054\n",
      "MSE for XGB_2: 301.20615900063456\n",
      "RMSE for XGB_1: 19.817337873851912\n",
      "RMSE for XGB_2: 17.35529195953311\n",
      "R2 for XGB_2: 0.7450398231876632\n",
      "EVS for XGB_2: 0.7450398349514994\n",
      "Local Model Results for Node 0 - AQI with Weighted Predictions:\n",
      "MSE for XGB_1: 635.361976792988\n",
      "MSE for XGB_2: 494.3666108921812\n",
      "RMSE for XGB_1: 25.20638761887526\n",
      "RMSE for XGB_2: 22.234356543245887\n",
      "R2 for XGB_2: 0.5922760087028126\n",
      "EVS for XGB_2: 0.5922760200793795\n",
      "Local Model Results for Node 0 - Highest tempreture: 12pm with Weighted Predictions:\n",
      "MSE for XGB_1: 1.7111792363749887\n",
      "MSE for XGB_2: 0.7202439301855786\n",
      "RMSE for XGB_1: 1.3081204976511105\n",
      "RMSE for XGB_2: 0.8486718624919638\n",
      "R2 for XGB_2: 0.9940475478327265\n",
      "EVS for XGB_2: 0.9940475488028172\n",
      "Local Model Results for Node 0 - Wind:km/h with Weighted Predictions:\n",
      "MSE for XGB_1: 13.999730988790905\n",
      "MSE for XGB_2: 4.748568849512047\n",
      "RMSE for XGB_1: 3.7416214384663373\n",
      "RMSE for XGB_2: 2.179121118596221\n",
      "R2 for XGB_2: 0.9179850794063817\n",
      "EVS for XGB_2: 0.9179851019610666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Model Results:\n",
      "Mean Squared Error (MSE) for Global Model: 177.1749664546841\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import the time module\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the folder path where the 22 files are located\n",
    "folder_path = ''\n",
    "\n",
    "# Initialize an empty list to store all the dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Loop through each file in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the Excel file into a dataframe\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Convert 'iranidate' to datetime and handle missing values\n",
    "        df['iranidate'] = pd.to_datetime(df['iranidate'], errors='coerce')\n",
    "        \n",
    "        def convert_to_numeric_date(date):\n",
    "            base_date = datetime(2000, 1, 1)\n",
    "            return (date - base_date).days\n",
    "        df['iranidate'] = df['iranidate'].apply(convert_to_numeric_date)\n",
    "        \n",
    "        # Encode 'node' column\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['node_encoded'] = label_encoder.fit_transform(df['node'])\n",
    "        \n",
    "        # Handling NaN values by finding the nearest non-empty cells in the same column\n",
    "        for col in ['CO', 'O3', 'SO2', 'PM10', 'PM2.5', 'AQI']:\n",
    "            for idx, value in df[col].items():\n",
    "                if pd.isnull(value):  \n",
    "                    upper_cell = df[col].iloc[:idx].last_valid_index()  \n",
    "                    lower_cell = df[col].iloc[idx + 1:].first_valid_index()  \n",
    "                    if upper_cell is not None and lower_cell is not None:  \n",
    "                        avg = (df.at[upper_cell, col] + df.at[lower_cell, col]) / 2  \n",
    "                        df.at[idx, col] = avg  \n",
    "        \n",
    "        # Append the modified dataframe to the list\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Check sample threshold\n",
    "your_threshold_value = 100\n",
    "if len(df) < your_threshold_value:\n",
    "    print(\"Insufficient samples in the dataset.\")\n",
    "else:\n",
    "    output_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM10', 'PM2.5', 'AQI', 'Highest tempreture: 12pm', 'Wind:km/h']\n",
    "    unique_nodes = df['node_encoded'].unique()  \n",
    "\n",
    "    # Dictionary to store weighted predictions for each node and column\n",
    "    weighted_predictions = {}\n",
    "    xgb_model_1 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.1, max_depth=5, alpha=10, n_estimators=100)\n",
    "    xgb_model_2 = xgb.XGBRegressor(colsample_bytree=0.8, learning_rate=0.1, max_depth=5, alpha=10, n_estimators=100)\n",
    "\n",
    "    for node_value in unique_nodes:\n",
    "        node_df = df[df['node_encoded'] == node_value]  \n",
    "        \n",
    "        # Dictionary to store predictions and true values for each column\n",
    "        columns_data = {}\n",
    "\n",
    "        for output_column in output_columns:\n",
    "            if node_df[output_column].isnull().any():\n",
    "                print(f\"NaN values found in {output_column} for Node {node_value}. Handle missing values before modeling.\")\n",
    "            else:\n",
    "                X = node_df[['iranidate', 'node_encoded']]\n",
    "                Y = node_df[[output_column]]  \n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "                \n",
    "                # XGBoost model for the first step\n",
    "                \n",
    "                xgb_model_1.fit(X_train, Y_train)\n",
    "                Y1_pred_xgb = xgb_model_1.predict(X_test)\n",
    "\n",
    "                # Secondary XGBoost model using the result of the first step\n",
    "                \n",
    "                xgb_model_2.fit(np.concatenate((X_test, Y1_pred_xgb.reshape(-1, 1)), axis=1), Y_test)\n",
    "                Y2_pred_xgb = xgb_model_2.predict(np.concatenate((X_test, Y1_pred_xgb.reshape(-1, 1)), axis=1))\n",
    "\n",
    "                # Calculate errors for the third XGBoost model\n",
    "                mse_xgb_1 = mean_squared_error(Y_test, Y1_pred_xgb)\n",
    "                mse_xgb_2 = mean_squared_error(Y_test, Y2_pred_xgb)\n",
    "                rmse_xgb_1 = np.sqrt(mse_xgb_1)\n",
    "                rmse_xgb_2 = np.sqrt(mse_xgb_2)\n",
    "                r2_xgb_2 = r2_score(Y_test, Y2_pred_xgb)\n",
    "                evs_xgb_2 = explained_variance_score(Y_test, Y2_pred_xgb)\n",
    "\n",
    "                # Store predictions and true values for each column in the dictionary\n",
    "                columns_data[output_column] = (Y2_pred_xgb, Y_test)\n",
    "\n",
    "                # Output results for the local model with weighted predictions\n",
    "                print(f\"Local Model Results for Node {node_value} - {output_column} with Weighted Predictions:\")\n",
    "                print(f\"MSE for XGB_1: {mse_xgb_1}\")\n",
    "                print(f\"MSE for XGB_2: {mse_xgb_2}\")\n",
    "                print(f\"RMSE for XGB_1: {rmse_xgb_1}\")\n",
    "                print(f\"RMSE for XGB_2: {rmse_xgb_2}\")\n",
    "                print(f\"R2 for XGB_2: {r2_xgb_2}\")\n",
    "                print(f\"EVS for XGB_2: {evs_xgb_2}\")\n",
    "\n",
    "                # Store weighted predictions for each node and column\n",
    "                if node_value not in weighted_predictions:\n",
    "                    weighted_predictions[node_value] = {output_column: (Y2_pred_xgb, Y_test)}\n",
    "                else:\n",
    "                    weighted_predictions[node_value][output_column] = (Y2_pred_xgb, Y_test)\n",
    "\n",
    "# Aggregate predictions for the global model using weighted average\n",
    "global_X_test = []\n",
    "global_Y_test = []\n",
    "\n",
    "for node, columns in weighted_predictions.items():\n",
    "    for column, (node_prediction, Y_test) in columns.items():\n",
    "        global_X_test.extend(node_prediction * r2_xgb_2)  # Apply weights using the R2 score from the third XGBoost model\n",
    "        global_Y_test.extend(Y_test.values)\n",
    "\n",
    "# Create and train the global model (Random Forest)\n",
    "global_model = RandomForestRegressor(random_state=42)\n",
    "global_model.fit(np.array(global_X_test).reshape(-1, 1), global_Y_test)  # Reshape for RF\n",
    "\n",
    "# Predict using the global model\n",
    "global_Y_pred = global_model.predict(np.array(global_X_test).reshape(-1, 1))\n",
    "global_mse = mean_squared_error(global_Y_test, global_Y_pred)\n",
    "\n",
    "# Print results for the global model\n",
    "print(\"Global Model Results:\")\n",
    "print(f\"Mean Squared Error (MSE) for Global Model: {global_mse}\")\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration of the program execution\n",
    "duration_seconds = end_time - start_time\n",
    "\n",
    "# Print the duration of the program execution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
